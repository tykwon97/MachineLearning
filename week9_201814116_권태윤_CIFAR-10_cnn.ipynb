{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"week9_201814116_권태윤_CIFAR-10_cnn.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FdZnDI8azinw","executionInfo":{"status":"ok","timestamp":1636476350955,"user_tz":-540,"elapsed":1450,"user":{"displayName":"날다람쥐","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12469158853173697691"}},"outputId":"f2602bae-cdb9-45ec-92be-b034d99be71d"},"source":["from google.colab import drive\n","drive.mount(\"/gdrive\", force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"5-Yj5-JyNCLs"},"source":["import os\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import (DataLoader, RandomSampler, TensorDataset)\n","from keras.datasets import mnist\n","from keras.datasets import cifar10\n","\n","\n","class MNIST_CNN(nn.Module):\n","\n","  def __init__(self, config):\n","    \n","    super(MNIST_CNN, self).__init__()\n","\n","    # 첫번째 층 설계: Convolutional NN\n","    # (batch, 32, 32, 3) -> (batch, 32, 32, 32) ->(batch, 32, 32, 64) -> (batch, 16, 16, 64)\n","    # 이곳을 채우세요.\n","\n","    self.conv1 = nn.Sequential()\n","    self.conv1.add_module(\"conv1-1\",nn.Conv2d(3,32,kernel_size=(3,3),stride=(1,1), padding=(1,1)))\n","    self.conv1.add_module(\"conv1-2\",nn.Conv2d(32,64,kernel_size=(3,3),stride=(1,1), padding=(1,1)))\n","    self.conv1.add_module(\"relu1\", nn.ReLU())\n","    self.conv1.add_module(\"maxpool1\", nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)))\n","\n","    # 두번째 층 설계: Convolutional NN\n","    # (batch, 16, 16, 64) -> (batch, 16, 16, 128) -> (batch, 8, 8, 128)\n","    # 이곳을 채우세요.\n","    self.conv2 = nn.Sequential()\n","    self.conv2.add_module(\"conv2\",nn.Conv2d(64,128, kernel_size=(3,3),stride=(1,1), padding=(1,1)))\n","    self.conv2.add_module(\"relu2\", nn.ReLU())\n","    self.conv2.add_module(\"maxpool2\", nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)))\n","\n","    # 세번째 층 설계: Convolutional NN\n","    # (batch, 8, 8, 128) -> (batch, 8, 8, 256) -> (batch, 4, 4, 256)\n","    # 이곳을 채우세요.\n","    self.conv3 = nn.Sequential()\n","    self.conv3.add_module(\"conv3\",nn.Conv2d(128,256, kernel_size=(3,3),stride=(1,1), padding=(1,1)))\n","    self.conv3.add_module(\"relu3\", nn.ReLU())\n","    self.conv3.add_module(\"maxpool3\", nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)))\n","\n","    # 네번째 층 설계: Fully-Connected NN\n","    # (batch, 8, 8, 64) -> (batch, 10)\n","    # 이곳을 채우세요.\n","    self.fnn = nn.Linear(4*4*256, 10, bias = True)\n","    #\n","\n","    # FNN 가중치 초기화\n","    nn.init.xavier_uniform_(self.fnn.weight)\n","\n","  def forward(self, input_features):\n","\n","    # 첫번째 Convolution\n","    output = self.conv1(input_features)\n","    \n","    # 두번째 Convolution\n","    output = self.conv2(output)\n","\n","    # 세번째 Convolution\n","    output = self.conv3(output)\n","    \n","    # 텐서를 1차원으로 펼치기: (batch, -1)\n","    # output.size(0): 배치 차원의 크기, -1: 해당 차원은 파이토치가 알아서 설정\n","    output = output.view(output.size(0), -1)\n","    hypothesis = self.fnn(output)\n","    return hypothesis"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5b7WN3AN_R6Q"},"source":["# 데이터 읽기 함수\n","def load_dataset():\n","  #cifar10에서 데이터를 로드\n","  #from keras.datasets import cifar10 이 필요\n","  (train_X, train_y), (test_X, test_y) = cifar10.load_data()\n","  train_X = np.transpose(train_X, (0,3,1,2))# (50000, 32, 32, 3) -> (50000, 3 , 32, 32)\n","  test_X = np.transpose(test_X, (0,3,1,2))  # (10000, 32, 32, 3) -> (10000, 3 , 32, 32)\n","  # shape변경 - http://taewan.kim/post/transpose_reshape/\n","  \n","  train_y = np.reshape(train_y, (50000,)) # (50000, 1) -> (50000,)\n","  test_y = np.reshape(test_y, (10000,)) # (10000, 1) -> (10000,)\n","\n","  print(train_X.shape) #number of image size : 32 x 32 #number of channel : 3\n","  print(train_y.shape) \n","  print(test_X.shape)\n","  print(test_y.shape)\n","  print()\n","  print(test_y)\n","\n","  train_X = torch.tensor(train_X, dtype=torch.float)\n","  train_y = torch.tensor(train_y, dtype=torch.long)\n","  test_X = torch.tensor(test_X, dtype=torch.float)\n","  test_y = torch.tensor(test_y, dtype=torch.long)\n","  \n","  return (train_X, train_y), (test_X, test_y)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fE5aJVyfRdn6"},"source":["# 모델 평가 결과 계산을 위해 텐서를 리스트로 변환하는 함수\n","def tensor2list(input_tensor):\n","    return input_tensor.cpu().detach().numpy().tolist()\n","\n","# 평가 수행 함수\n","def do_test(model, test_dataloader):\n","\n","  # 평가 모드 셋팅\n","  model.eval()\n","\n","  # Batch 별로 예측값과 정답을 저장할 리스트 초기화\n","  predicts, golds = [], []\n","  \n","  with torch.no_grad():\n","\n","    for step, batch in enumerate(test_dataloader):\n","  \n","      # .cuda()를 통해 메모리에 업로드\n","      batch = tuple(t.cuda() for t in batch)\n","\n","      input_features, labels = batch\n","      hypothesis = model(input_features)\n","\n","      # ont-hot 표현으로 변경\n","      logits = torch.argmax(hypothesis,-1)\n","\n","      x = tensor2list(logits)\n","      y = tensor2list(labels)\n","\n","      # 예측값과 정답을 리스트에 추가\n","      predicts.extend(x)\n","      golds.extend(y)\n","    \n","    print(\"PRED=\",predicts)\n","    print(\"GOLD=\",golds)\n","    print(\"Accuracy= {0:f}\\n\".format(accuracy_score(golds, predicts)))\n","\n","# 모델 평가 함수\n","def test(config):\n","\n","  model = MNIST_CNN(config).cuda()\n","\n","  # 저장된 모델 가중치 로드\n","  model.load_state_dict(torch.load(os.path.join(config[\"output_dir\"], config[\"model_name\"])))\n","\n","  # 데이터 load\n","  (_, _), (features, labels) = load_dataset()\n","  \n","  test_features = TensorDataset(features, labels)\n","  test_dataloader = DataLoader(test_features, shuffle=True, batch_size=config[\"batch_size\"])\n","  \n","  do_test(model, test_dataloader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5f7fNFnA_Lhe"},"source":["# 모델 학습 함수\n","def train(config):\n","\n","  # 모델 생성\n","  model = MNIST_CNN(config).cuda()\n","\n","  # 데이터 읽기\n","  (input_features, labels), (_, _) = load_dataset()\n","\n","  # TensorDataset/DataLoader를 통해 배치(batch) 단위로 데이터를 나누고 셔플(shuffle)\n","  train_features = TensorDataset(input_features, labels)\n","  train_dataloader = DataLoader(train_features, shuffle=True, batch_size=config[\"batch_size\"])\n","\n","  # 크로스엔트로피 비용 함수 \n","  loss_func = nn.CrossEntropyLoss()\n","  # 옵티마이저 함수 (역전파 알고리즘을 수행할 함수)\n","  optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learn_rate\"])\n","\n","  for epoch in range(config[\"epoch\"]+1):\n","\n","    # 학습 모드 셋팅\n","    model.train()\n","  \n","    # epoch 마다 평균 비용을 저장하기 위한 리스트\n","    costs = []\n","\n","    for (step, batch) in enumerate(train_dataloader):\n","\n","      # batch = (input_features[step], labels[step])*batch_size\n","      # .cuda()를 통해 메모리에 업로드\n","      batch = tuple(t.cuda() for t in batch)\n","\n","      # 각 feature 저장\n","      input_features, labels = batch\n","\n","      # 역전파 변화도 초기화\n","      # .backward() 호출 시, 변화도 버퍼에 데이터가 계속 누적한 것을 초기화\n","      optimizer.zero_grad()\n","\n","      # H(X) 계산: forward 연산\n","      hypothesis = model(input_features)\n","      # 비용 계산\n","      cost = loss_func(hypothesis, labels)\n","      # 역전파 수행\n","      cost.backward()\n","      optimizer.step()\n","   \n","      # 현재 batch의 스텝 별 loss 저장\n","      costs.append(cost.data.item())\n","    \n","    # 에폭마다 평균 비용 출력하고 모델을 저장\n","    print(\"Average Loss= {0:f}\".format(np.mean(costs)))\n","    torch.save(model.state_dict(), os.path.join(config[\"output_dir\"], \"epoch_{0:d}.pt\".format(epoch)))\n","    do_test(model, train_dataloader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"12CWW5J9KVuC6TBEpopwohwIFcSwts6g5"},"id":"5wbpqmro-xhg","executionInfo":{"status":"ok","timestamp":1636476715102,"user_tz":-540,"elapsed":363755,"user":{"displayName":"날다람쥐","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12469158853173697691"}},"outputId":"a168c9e6-0f89-4ca0-dd97-e97a47766e98"},"source":["if(__name__==\"__main__\"):\n","\n","    root_dir = \"/gdrive/My Drive/colab/cnn/cifar\"\n","    output_dir = os.path.join(root_dir, \"output\")\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    config = {\"mode\": \"train\",\n","              \"model_name\":\"epoch_{0:d}.pt\".format(10),\n","              \"output_dir\":output_dir,\n","              \"learn_rate\":0.001,\n","              \"batch_size\":32,\n","              \"epoch\":10,\n","              }\n","\n","    if(config[\"mode\"] == \"train\"):\n","        train(config)\n","    else:\n","        test(config)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"k3_-VwliQJ8X"},"source":[""],"execution_count":null,"outputs":[]}]}
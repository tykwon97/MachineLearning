{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"week9_201814116_권태윤_mnist_cnn.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FdZnDI8azinw","executionInfo":{"status":"ok","timestamp":1636476861229,"user_tz":-540,"elapsed":1459,"user":{"displayName":"날다람쥐","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12469158853173697691"}},"outputId":"244072c5-a332-4d7e-ddb1-5c9c96ad7e25"},"source":["from google.colab import drive\n","drive.mount(\"/gdrive\", force_remount=True)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"5-Yj5-JyNCLs","executionInfo":{"status":"ok","timestamp":1636476861231,"user_tz":-540,"elapsed":34,"user":{"displayName":"날다람쥐","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12469158853173697691"}}},"source":["import os\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import (DataLoader, RandomSampler, TensorDataset)\n","from keras.datasets import mnist\n","\n","class MNIST_CNN(nn.Module):\n","\n","  def __init__(self, config):\n","    \n","    super(MNIST_CNN, self).__init__()\n","\n","    # 첫번째 층 설계: Convolutional NN\n","    # (batch, 28, 28, 1) -> (batch, 28, 28, 32) -> (batch, 14, 14, 32)\n","    # 이곳을 채우세요.\n","\n","    self.conv1 = nn.Sequential()\n","    self.conv1.add_module(\"conv1\",nn.Conv2d(1,32,kernel_size=(3,3),stride=(1,1), padding=(1,1)))\n","    self.conv1.add_module(\"relu1\", nn.ReLU())\n","    self.conv1.add_module(\"maxpool1\", nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)))\n","\n","    # self.conv1 - nn.Sequential(\n","    #     nn.Conv2d(1, 32 , kernel_size=3, stride =1, padding=1),\n","    #     nn.ReLU(),\n","    #     nn.MaxPool2d(kernel_size=2, stride=2))\n","    #\n","\n","    # 두번째 층 설계: Convolutional NN\n","    # (batch, 14, 14, 32) -> (batch, 14, 14, 64) -> (batch, 7, 7, 64)\n","    # 이곳을 채우세요.\n","    self.conv2 = nn.Sequential()\n","    self.conv2.add_module(\"conv2\",nn.Conv2d(32,64, kernel_size=(3,3),stride=(1,1), padding=(1,1)))\n","    self.conv2.add_module(\"relu2\", nn.ReLU())\n","    self.conv2.add_module(\"maxpool2\", nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)))\n","\n","    # self.conv2 - nn.Sequential(\n","    #     nn.Conv2d(32, 64 , kernel_size=3, stride =1, padding=1),\n","    #     nn.ReLU(),\n","    #     nn.MaxPool2d(kernel_size=2, stride=2))\n","    #\n","\n","    # 세번째 층 설계: Fully-Connected NN\n","    # (batch, 7, 7, 64) -> (batch, 10)\n","    # 이곳을 채우세요.\n","    self.fnn = nn.Linear(7*7*64, 10, bias = True)\n","    # 모델을 선언 및 초기화. 단순 선형 회귀이므로 input_dim=7*7*64, output_dim=1.\n","    #\n","\n","    # FNN 가중치 초기화\n","    nn.init.xavier_uniform_(self.fnn.weight)\n","    #설명(공식 문서) - https://pytorch.org/docs/stable/nn.init.html#:~:text=torch.nn.init.xavier_uniform_(tensor%2C%20gain%3D1.0)\n","\n","  def forward(self, input_features):\n","\n","    # 첫번째 Convolution\n","    output = self.conv1(input_features)\n","    \n","    # 두번째 Convolution\n","    output = self.conv2(output)\n","    \n","    # 텐서를 1차원으로 펼치기: (batch, -1)\n","    # output.size(0): 배치 차원의 크기, -1: 해당 차원은 파이토치가 알아서 설정\n","    output = output.view(output.size(0), -1)\n","    hypothesis = self.fnn(output)\n","   \n","    return hypothesis"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"5b7WN3AN_R6Q","executionInfo":{"status":"ok","timestamp":1636476861233,"user_tz":-540,"elapsed":34,"user":{"displayName":"날다람쥐","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12469158853173697691"}}},"source":["# 데이터 읽기 함수\n","def load_dataset():\n","\n","  (train_X, train_y), (test_X, test_y) = mnist.load_data()\n","  print(train_X.shape) # (60000, 28, 28)\n","  print(train_y.shape) # (60000,10)\n","  print(test_X.shape) # (10000, 28, 28)\n","  print(test_y.shape) # (10000,10)\n","  \n","  # 채널 추가\n","  # 이곳을 채우세요\n","  train_X = train_X.reshape(-1, 1, 28, 28) #(60000, 1, 28, 28)\n","  test_X  = test_X.reshape(-1, 1,  28, 28) #(60000, 1, 28, 28)\n","  #.\n","  print(train_X.shape)\n","  print(test_X.shape)\n","  train_X = torch.tensor(train_X, dtype=torch.float)\n","  train_y = torch.tensor(train_y, dtype=torch.long)\n","  test_X = torch.tensor(test_X, dtype=torch.float)\n","  test_y = torch.tensor(test_y, dtype=torch.long)\n","  \n","  return (train_X, train_y), (test_X, test_y)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"fE5aJVyfRdn6","executionInfo":{"status":"ok","timestamp":1636476861235,"user_tz":-540,"elapsed":27,"user":{"displayName":"날다람쥐","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12469158853173697691"}}},"source":["# 모델 평가 결과 계산을 위해 텐서를 리스트로 변환하는 함수\n","def tensor2list(input_tensor):\n","    return input_tensor.cpu().detach().numpy().tolist()\n","\n","# 평가 수행 함수\n","def do_test(model, test_dataloader):\n","\n","  # 평가 모드 셋팅\n","  model.eval()\n","\n","  # Batch 별로 예측값과 정답을 저장할 리스트 초기화\n","  predicts, golds = [], []\n","  \n","  with torch.no_grad():\n","\n","    for step, batch in enumerate(test_dataloader):\n","  \n","      # .cuda()를 통해 메모리에 업로드\n","      batch = tuple(t.cuda() for t in batch)\n","\n","      input_features, labels = batch\n","      hypothesis = model(input_features)\n","\n","      # ont-hot 표현으로 변경\n","      logits = torch.argmax(hypothesis,-1)\n","\n","      x = tensor2list(logits)\n","      y = tensor2list(labels)\n","\n","      # 예측값과 정답을 리스트에 추가\n","      predicts.extend(x)\n","      golds.extend(y)\n","    \n","    print(\"PRED=\",predicts)\n","    print(\"GOLD=\",golds)\n","    print(\"Accuracy= {0:f}\\n\".format(accuracy_score(golds, predicts)))\n","\n","# 모델 평가 함수\n","def test(config):\n","\n","  model = MNIST_CNN(config).cuda()\n","\n","  # 저장된 모델 가중치 로드\n","  model.load_state_dict(torch.load(os.path.join(config[\"output_dir\"], config[\"model_name\"])))\n","\n","  # 데이터 load\n","  (_, _), (features, labels) = load_dataset()\n","  \n","  test_features = TensorDataset(features, labels)\n","  test_dataloader = DataLoader(test_features, shuffle=True, batch_size=config[\"batch_size\"])\n","  \n","  do_test(model, test_dataloader)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"5f7fNFnA_Lhe","executionInfo":{"status":"ok","timestamp":1636476861237,"user_tz":-540,"elapsed":26,"user":{"displayName":"날다람쥐","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12469158853173697691"}}},"source":["# 모델 학습 함수\n","def train(config):\n","\n","  # 모델 생성\n","  model = MNIST_CNN(config).cuda()\n","\n","  # 데이터 읽기\n","  (input_features, labels), (_, _) = load_dataset()\n","\n","  # TensorDataset/DataLoader를 통해 배치(batch) 단위로 데이터를 나누고 셔플(shuffle)\n","  train_features = TensorDataset(input_features, labels)\n","  train_dataloader = DataLoader(train_features, shuffle=True, batch_size=config[\"batch_size\"])\n","\n","  # 크로스엔트로피 비용 함수 \n","  loss_func = nn.CrossEntropyLoss()\n","  # 옵티마이저 함수 (역전파 알고리즘을 수행할 함수)\n","  optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learn_rate\"])\n","\n","  for epoch in range(config[\"epoch\"]+1):\n","\n","    # 학습 모드 셋팅\n","    model.train()\n","  \n","    # epoch 마다 평균 비용을 저장하기 위한 리스트\n","    costs = []\n","\n","    for (step, batch) in enumerate(train_dataloader):\n","\n","      # batch = (input_features[step], labels[step])*batch_size\n","      # .cuda()를 통해 메모리에 업로드\n","      batch = tuple(t.cuda() for t in batch)\n","      # 각 feature 저장\n","      input_features, labels = batch\n","\n","      # 역전파 변화도 초기화\n","      # .backward() 호출 시, 변화도 버퍼에 데이터가 계속 누적한 것을 초기화\n","      optimizer.zero_grad()\n","\n","      # H(X) 계산: forward 연산\n","      hypothesis = model(input_features)\n","      # 비용 계산\n","      cost = loss_func(hypothesis, labels)\n","      # 역전파 수행\n","      cost.backward()\n","      optimizer.step()\n","   \n","      # 현재 batch의 스텝 별 loss 저장\n","      costs.append(cost.data.item())\n","    \n","    # 에폭마다 평균 비용 출력하고 모델을 저장\n","    print(\"Average Loss= {0:f}\".format(np.mean(costs)))\n","    torch.save(model.state_dict(), os.path.join(config[\"output_dir\"], \"epoch_{0:d}.pt\".format(epoch)))\n","    do_test(model, train_dataloader)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1VtqprZ8I2mek8KBHgTVwBoSVj3a6XAL1"},"id":"5wbpqmro-xhg","executionInfo":{"status":"ok","timestamp":1636477002406,"user_tz":-540,"elapsed":141191,"user":{"displayName":"날다람쥐","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12469158853173697691"}},"outputId":"06d37b67-1a30-4c0a-b254-0c2f37623a39"},"source":["if(__name__==\"__main__\"):\n","\n","    root_dir = \"/gdrive/My Drive/colab/cnn/mnist\"\n","    output_dir = os.path.join(root_dir, \"output\")\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    config = {\"mode\": \"train\",\n","              \"model_name\":\"epoch_{0:d}.pt\".format(10),\n","              \"output_dir\":output_dir,\n","              \"learn_rate\":0.001,\n","              \"batch_size\":32,\n","              \"epoch\":10,\n","              }\n","\n","    if(config[\"mode\"] == \"train\"):\n","        train(config)\n","    else:\n","        test(config)"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"k3_-VwliQJ8X","executionInfo":{"status":"ok","timestamp":1636477002408,"user_tz":-540,"elapsed":36,"user":{"displayName":"날다람쥐","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12469158853173697691"}}},"source":[""],"execution_count":11,"outputs":[]}]}
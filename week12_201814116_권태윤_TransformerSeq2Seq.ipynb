{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week12_201814116_권태윤_TransformerSeq2Seq (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j65i49dU8Cjs",
        "outputId": "13151629-eb55-4744-c580-a8d25522e9b3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\", force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zVeC5Mf8C-S"
      },
      "source": [
        "from torch.utils.data import (DataLoader, TensorDataset)\n",
        "from torch import nn\n",
        "from tqdm import tqdm #status bar\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "\n",
        "class TransformerChat(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        # 전체 단어(음절) 개수\n",
        "        self.vocab_size = config[\"vocab_size\"]\n",
        "\n",
        "        # 단어(음절) 벡터 크기\n",
        "        self.embedding_size = config['embedding_size']\n",
        "\n",
        "        # Transformer의 Attention Head 개수\n",
        "        self.num_heads = config['num_heads']\n",
        "\n",
        "        # Transformer Encoder의 Layer 수\n",
        "        self.num_encoder_layers = config['num_encoder_layers']\n",
        "\n",
        "        # Transformer Decoder의 Layer 수\n",
        "        self.num_decoder_layers = config['num_decoder_layers']\n",
        "\n",
        "        # 입력 Sequence의 최대 길이\n",
        "        self.max_length = config['max_length']\n",
        "\n",
        "        # Transformer 내부 FNN 크기\n",
        "        self.hidden_size = config['hidden_size']\n",
        "\n",
        "        # Token Embedding Matrix 선언\n",
        "        self.embeddings = nn.Embedding(self.vocab_size, self.embedding_size)\n",
        "\n",
        "        # Transformer Encoder-Decoder 설계(선언)\n",
        "        self.transformer = nn.Transformer(d_model=self.embedding_size, nhead=self.num_heads, num_encoder_layers=self.num_encoder_layers,\n",
        "                                          num_decoder_layers=self.num_decoder_layers, dim_feedforward=self.hidden_size)\n",
        "       \n",
        "        # 입력 길이 L에 대한 (L X L) mask 생성: 이전 토큰들의 정보만을 반영하기 위한 mask\n",
        "        #       [[1, -inf, -inf, -inf],\n",
        "        #        [1,    1, -inf, -inf],\n",
        "        #               ......\n",
        "        #        [1,    1,    1,    1]]\n",
        "        # 이곳을 채우세요.\n",
        "        self.mask = self.transformer.generate_square_subsequent_mask(self.max_length).cuda()\n",
        "\n",
        "        # 전체 단어 분포로 변환하기 위한 linear\n",
        "        # 이곳을 채우세요.\n",
        "        self.projection_layer = nn.Linear(self.embedding_size, self.vocab_size)\n",
        "\n",
        "    def forward(self, enc_inputs, dec_inputs):\n",
        "\n",
        "        # enc_inputs: [batch, seq_len], dec_inputs: [batch, seq_len]\n",
        "        # enc_input_features: [batch, seq_len, emb_size] -> [seq_len, batch, emb_size]\n",
        "        # 이곳을 채우세요.\n",
        "        enc_input_features = self.embeddings(enc_inputs).transpose(0,1)\n",
        "\n",
        "        # dec_input_features: [batch, seq_len, emb_size] -> [seq_len, batch, emb_size]\n",
        "        # 이곳을 채우세요.\n",
        "        dec_input_features = self.embeddings(dec_inputs).transpose(0,1)\n",
        "\n",
        "        # dec_output_features: [seq_len, batch, emb_size]\n",
        "        dec_output_features = self.transformer(src=enc_input_features, tgt=dec_input_features, src_mask = self.mask, tgt_mask = self.mask)\n",
        "\n",
        "        # hypothesis : [seq_len, batch, vocab_size]\n",
        "        hypothesis = self.projection_layer(dec_output_features)\n",
        "\n",
        "        return hypothesis"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmYHzEcU8nRp"
      },
      "source": [
        "# 어휘사전(vocabulary) 생성 함수\n",
        "def load_vocab(file_dir):\n",
        "\n",
        "    with open(file_dir,'r',encoding='utf8') as vocab_file:\n",
        "        char2idx = {}\n",
        "        idx2char = {}\n",
        "        index = 0\n",
        "        for char in vocab_file:\n",
        "            char = char.strip()\n",
        "            char2idx[char] = index\n",
        "            idx2char[index] = char\n",
        "            index+=1\n",
        "\n",
        "    return char2idx, idx2char\n",
        "\n",
        "# 문자 입력열을 인덱스로 변환하는 함수\n",
        "def convert_data2feature(config, input_sequence, char2idx, decoder_input=False):\n",
        "\n",
        "    # 고정 길이 벡터 생성\n",
        "    input_features = np.zeros(config[\"max_length\"], dtype=np.int)\n",
        "\n",
        "    if decoder_input:\n",
        "        # Decoder Input은 Target Sequence에서 Right Shift\n",
        "        # Target Sequence :         [\"안\",\"녕\",\"하\",\"세\",\"요\", \"</S>\" ]\n",
        "        # Decoder Input Sequence :  [\"<S>\", \"안\",\"녕\",\"하\",\"세\",\"요\"]\n",
        "        # 이곳을 채우세요.\n",
        "        input_sequence = \" \".join([\"<S>\"] + input_sequence.split()[:-1])\n",
        "\n",
        "    for idx,token in enumerate(input_sequence.split()):\n",
        "        if token in char2idx.keys():\n",
        "            input_features[idx] = char2idx[token]\n",
        "        else:\n",
        "            input_features[idx] = char2idx['<UNK>']\n",
        "\n",
        "    return input_features\n",
        "\n",
        "# 데이터 읽기 함수\n",
        "def load_dataset(config):\n",
        "\n",
        "    # 어휘사전 읽어오기\n",
        "    char2idx, idx2char = load_vocab(config['vocab_file'])\n",
        "\n",
        "    file_dir = config['train_file']\n",
        "    data_file = open(file_dir,'r',encoding='utf8').readlines()\n",
        "\n",
        "    # 데이터를 저장하기 위한 리스트 생성\n",
        "    enc_inputs, dec_inputs, dec_outputs = [], [], []\n",
        "\n",
        "    for line in tqdm(data_file):\n",
        "\n",
        "        line = line.strip().split('\\t')\n",
        "\n",
        "        input_sequence = line[0]\n",
        "        output_sequence = line[1]\n",
        "\n",
        "        enc_inputs.append(convert_data2feature(config, input_sequence, char2idx))\n",
        "        dec_inputs.append(convert_data2feature(config, output_sequence, char2idx, True))\n",
        "        dec_outputs.append(convert_data2feature(config, output_sequence, char2idx))\n",
        "\n",
        "    # 전체 데이터를 저장하고 있는 리스트를 텐서 형태로 변환\n",
        "    enc_inputs = torch.tensor(enc_inputs, dtype=torch.long)\n",
        "    dec_inputs = torch.tensor(dec_inputs, dtype=torch.long)\n",
        "    dec_outputs = torch.tensor(dec_outputs, dtype=torch.long)\n",
        "\n",
        "    return enc_inputs, dec_inputs, dec_outputs, char2idx, idx2char"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ-bIKnw-1D8"
      },
      "source": [
        "# 텐서를 리스트로 변환하는 함수\n",
        "def tensor2list(input_tensor):\n",
        "    return input_tensor.cpu().detach().numpy().tolist()\n",
        "\n",
        "def do_test(config, model, word2idx, idx2word, input_sequence=\"오늘 약속있으세요?\"):\n",
        "\n",
        "    # 평가 모드 셋팅\n",
        "    model.eval()\n",
        "\n",
        "    # 입력된 문자열의 음절을 공백 단위 토큰으로 변환. 공백은 <SP>로 변환: \"오늘 약속\" -> \"오 늘 <SP> 약 속\"\n",
        "    input_sequence = \" \".join([e if e != \" \" else \"<SP>\" for e in input_sequence])\n",
        "\n",
        "    # 텐서 변환: [1, seq_len]\n",
        "    enc_inputs = torch.tensor([convert_data2feature(config, input_sequence, word2idx)], dtype=torch.long).cuda()\n",
        "    \n",
        "    # input_ids : [1, seq_len] -> 첫번째 디코더 입력 \"<S>\" 만들기\n",
        "    dec_inputs = torch.tensor([convert_data2feature(config, \"\", word2idx, True)], dtype=torch.long).cuda()\n",
        "    \n",
        "    # 시스템 응답 문자열 초기화\n",
        "    response = ''\n",
        "\n",
        "    # 최대 입력 길이 만큼 Decoding Loop\n",
        "    for decoding_step in range(config['max_length']-1):\n",
        "\n",
        "        # dec_outputs: [vocab_size]\n",
        "        dec_outputs = model(enc_inputs, dec_inputs)[decoding_step, 0, :]\n",
        "        # 가장 큰 출력을 갖는 인덱스 얻어오기\n",
        "        dec_output_idx = np.argmax(tensor2list(dec_outputs))\n",
        "\n",
        "        # 생성된 토큰은 dec_inputs에 추가 (첫번째 차원은 배치)\n",
        "        dec_inputs[0][decoding_step+1] = dec_output_idx\n",
        "\n",
        "        # </S> 심볼 생성 시, Decoding 종료\n",
        "        if idx2word[dec_output_idx] == \"</S>\":\n",
        "            break\n",
        "\n",
        "        # 생성 토큰 추가\n",
        "        response += idx2word[dec_output_idx]\n",
        "    \n",
        "    # <SP>를 공백으로 변환한 후 응답 문자열 출력\n",
        "    print(response.replace(\"<SP>\", \" \"))\n",
        "\n",
        "def test(config):\n",
        "\n",
        "    # 어휘사전 읽어오기\n",
        "    word2idx, idx2word = load_vocab(config['vocab_file'])\n",
        "\n",
        "    # Transformer Seq2Seq 모델 객체 생성\n",
        "    model = TransformerChat(config).cuda()\n",
        "\n",
        "    # 학습한 모델 파일로부터 가중치 불러옴\n",
        "    model.load_state_dict(torch.load(os.path.join(config[\"output_dir\"], config[\"trained_model_name\"])))\n",
        "\n",
        "    while(True):\n",
        "        input_sequence = input(\"문장을 입력하세요. (종료는 exit을 입력하세요.) : \")\n",
        "        if input_sequence == 'exit':\n",
        "            break\n",
        "        do_test(config, model, word2idx, idx2word, input_sequence)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow01KJjz-416"
      },
      "source": [
        "def train(config):\n",
        "\n",
        "    # Transformer Seq2Seq 모델 객체 생성\n",
        "    model = TransformerChat(config).cuda()\n",
        "\n",
        "    # 데이터 읽기\n",
        "    enc_inputs, dec_inputs, dec_outputs, word2idx, idx2word = load_dataset(config)\n",
        "\n",
        "    # TensorDataset/DataLoader를 통해 배치(batch) 단위로 데이터를 나누고 셔플(shuffle)\n",
        "    train_features = TensorDataset(enc_inputs, dec_inputs, dec_outputs)\n",
        "    train_dataloader = DataLoader(train_features, shuffle=True, batch_size=config[\"batch_size\"])\n",
        "\n",
        "    # 크로스엔트로피 손실 함수\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "    # 옵티마이저 함수 지정\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learn_rate\"])\n",
        "\n",
        "    for epoch in range(config[\"epoch\"] + 1):\n",
        "\n",
        "        for (step, batch) in enumerate(train_dataloader):\n",
        "\n",
        "            # 학습 모드 셋팅\n",
        "            model.train()\n",
        "          \n",
        "            # batch = (enc_inputs[step], dec_inputs[step], dec_outputs)*batch_size\n",
        "            # .cuda()를 통해 메모리에 업로드\n",
        "            batch = tuple(t.cuda() for t in batch)\n",
        "\n",
        "            # 역전파 변화도 초기화\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            enc_inputs, dec_inputs, dec_outputs = batch\n",
        "\n",
        "            # hypothesis: [seq_len, batch, vocab_size] -> [seq_len*batch, vocab_size]\n",
        "            # 이곳을 채우세요.\n",
        "            hypothesis = model(enc_inputs, dec_inputs).view(-1, config['vocab_size'])\n",
        "\n",
        "            # labels: [batch, seq_len] -> [seq_len, batch] -> [seq_len(max_length)*batch]\n",
        "            labels = dec_outputs.transpose(0, 1)\n",
        "            labels = labels.reshape(config[\"max_length\"]*dec_inputs.size(0))\n",
        "\n",
        "            # 비용 계산 및 역전파 수행: cross_entopy 내부에서 labels를 원핫벡터로 변환 (골드레이블은 항상 1차원으로 입력)\n",
        "            loss = loss_func(hypothesis, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # 200 배치마다 중간 결과 출력\n",
        "            if (step+1)% 200 == 0:\n",
        "                print(\"Current Step : {0:d} / {1:d}\\tCurrent Loss : {2:f}\".format(step+1, int(len(enc_inputs) / config['batch_size']), loss.item()))\n",
        "                # 생성 문장을 확인하기 위한 함수 호출\n",
        "                # do_test(config, model, word2idx, idx2word)\n",
        "\n",
        "        # 에폭마다 가중치 저장\n",
        "        torch.save(model.state_dict(), os.path.join(config[\"output_dir\"], \"epoch_{0:d}.pt\".format(epoch)))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fk1BLZ-VrHe",
        "outputId": "3f3b2b1a-f24e-4b0c-819f-5150f97b478c"
      },
      "source": [
        "if(__name__==\"__main__\"):\n",
        "\n",
        "    root_dir = \"/gdrive/My Drive/colab/transformer/chatbot/\"\n",
        "    output_dir = os.path.join(root_dir, \"output\")\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    config = {\"mode\": \"train\",\n",
        "              \"vocab_file\": os.path.join(root_dir, \"vocab.txt\"),\n",
        "              \"train_file\": os.path.join(root_dir, \"train.txt\"),\n",
        "              \"trained_model_name\":\"epoch_{}.pt\".format(10),\n",
        "              \"output_dir\":output_dir,\n",
        "              \"epoch\": 10,\n",
        "              \"learn_rate\":0.00005,\n",
        "              \"num_encoder_layers\": 6,\n",
        "              \"num_decoder_layers\": 6,\n",
        "              \"num_heads\": 4,\n",
        "              \"max_length\": 20,\n",
        "              \"batch_size\": 128,\n",
        "              \"embedding_size\": 256,\n",
        "              \"hidden_size\": 512,\n",
        "              \"vocab_size\": 4427\n",
        "            }\n",
        "\n",
        "    if(config[\"mode\"] == \"train\"):\n",
        "        train(config)\n",
        "    else:\n",
        "        test(config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 547958/547958 [00:11<00:00, 48615.66it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Step : 200 / 1\tCurrent Loss : 2.751000\n",
            "Current Step : 400 / 1\tCurrent Loss : 2.385847\n",
            "Current Step : 600 / 1\tCurrent Loss : 2.223494\n",
            "Current Step : 800 / 1\tCurrent Loss : 2.136447\n",
            "Current Step : 1000 / 1\tCurrent Loss : 2.062451\n",
            "Current Step : 1200 / 1\tCurrent Loss : 1.960630\n",
            "Current Step : 1400 / 1\tCurrent Loss : 1.831970\n",
            "Current Step : 1600 / 1\tCurrent Loss : 1.994858\n",
            "Current Step : 1800 / 1\tCurrent Loss : 1.913600\n",
            "Current Step : 2000 / 1\tCurrent Loss : 1.943497\n",
            "Current Step : 2200 / 1\tCurrent Loss : 1.841079\n",
            "Current Step : 2400 / 1\tCurrent Loss : 1.911761\n",
            "Current Step : 2600 / 1\tCurrent Loss : 1.941825\n",
            "Current Step : 2800 / 1\tCurrent Loss : 1.823119\n",
            "Current Step : 3000 / 1\tCurrent Loss : 1.873292\n",
            "Current Step : 3200 / 1\tCurrent Loss : 1.710339\n",
            "Current Step : 3400 / 1\tCurrent Loss : 1.878893\n",
            "Current Step : 3600 / 1\tCurrent Loss : 1.749028\n",
            "Current Step : 3800 / 1\tCurrent Loss : 1.787916\n",
            "Current Step : 4000 / 1\tCurrent Loss : 1.727744\n",
            "Current Step : 4200 / 1\tCurrent Loss : 1.797404\n",
            "Current Step : 200 / 1\tCurrent Loss : 1.717459\n",
            "Current Step : 400 / 1\tCurrent Loss : 1.827304\n",
            "Current Step : 600 / 1\tCurrent Loss : 1.782387\n",
            "Current Step : 800 / 1\tCurrent Loss : 1.766205\n",
            "Current Step : 1000 / 1\tCurrent Loss : 1.642490\n",
            "Current Step : 1200 / 1\tCurrent Loss : 1.692661\n",
            "Current Step : 1400 / 1\tCurrent Loss : 1.603402\n",
            "Current Step : 1600 / 1\tCurrent Loss : 1.563925\n",
            "Current Step : 1800 / 1\tCurrent Loss : 1.764532\n",
            "Current Step : 2000 / 1\tCurrent Loss : 1.787437\n",
            "Current Step : 2200 / 1\tCurrent Loss : 1.642750\n",
            "Current Step : 2400 / 1\tCurrent Loss : 1.616027\n",
            "Current Step : 2600 / 1\tCurrent Loss : 1.640681\n",
            "Current Step : 2800 / 1\tCurrent Loss : 1.842723\n",
            "Current Step : 3000 / 1\tCurrent Loss : 1.710390\n",
            "Current Step : 3200 / 1\tCurrent Loss : 1.713541\n",
            "Current Step : 3400 / 1\tCurrent Loss : 1.655979\n",
            "Current Step : 3600 / 1\tCurrent Loss : 1.756700\n",
            "Current Step : 3800 / 1\tCurrent Loss : 1.636229\n",
            "Current Step : 4000 / 1\tCurrent Loss : 1.724927\n",
            "Current Step : 4200 / 1\tCurrent Loss : 1.494712\n",
            "Current Step : 200 / 1\tCurrent Loss : 1.676784\n",
            "Current Step : 400 / 1\tCurrent Loss : 1.588186\n",
            "Current Step : 600 / 1\tCurrent Loss : 1.701373\n",
            "Current Step : 800 / 1\tCurrent Loss : 1.685731\n",
            "Current Step : 1000 / 1\tCurrent Loss : 1.670968\n",
            "Current Step : 1200 / 1\tCurrent Loss : 1.683643\n",
            "Current Step : 1400 / 1\tCurrent Loss : 1.634042\n",
            "Current Step : 1600 / 1\tCurrent Loss : 1.645669\n",
            "Current Step : 1800 / 1\tCurrent Loss : 1.692377\n",
            "Current Step : 2000 / 1\tCurrent Loss : 1.567136\n",
            "Current Step : 2200 / 1\tCurrent Loss : 1.682606\n",
            "Current Step : 2400 / 1\tCurrent Loss : 1.621395\n",
            "Current Step : 2600 / 1\tCurrent Loss : 1.609743\n",
            "Current Step : 2800 / 1\tCurrent Loss : 1.667523\n",
            "Current Step : 3000 / 1\tCurrent Loss : 1.636883\n",
            "Current Step : 3200 / 1\tCurrent Loss : 1.642456\n",
            "Current Step : 3400 / 1\tCurrent Loss : 1.596499\n",
            "Current Step : 3600 / 1\tCurrent Loss : 1.609560\n",
            "Current Step : 3800 / 1\tCurrent Loss : 1.649358\n",
            "Current Step : 4000 / 1\tCurrent Loss : 1.654582\n",
            "Current Step : 4200 / 1\tCurrent Loss : 1.642449\n",
            "Current Step : 200 / 1\tCurrent Loss : 1.624697\n",
            "Current Step : 400 / 1\tCurrent Loss : 1.524236\n",
            "Current Step : 600 / 1\tCurrent Loss : 1.498275\n",
            "Current Step : 800 / 1\tCurrent Loss : 1.549690\n",
            "Current Step : 1000 / 1\tCurrent Loss : 1.658186\n",
            "Current Step : 1200 / 1\tCurrent Loss : 1.588612\n",
            "Current Step : 1400 / 1\tCurrent Loss : 1.616486\n",
            "Current Step : 1600 / 1\tCurrent Loss : 1.440152\n",
            "Current Step : 1800 / 1\tCurrent Loss : 1.556049\n",
            "Current Step : 2000 / 1\tCurrent Loss : 1.561541\n",
            "Current Step : 2200 / 1\tCurrent Loss : 1.575820\n",
            "Current Step : 2400 / 1\tCurrent Loss : 1.613343\n",
            "Current Step : 2600 / 1\tCurrent Loss : 1.829158\n",
            "Current Step : 2800 / 1\tCurrent Loss : 1.578300\n",
            "Current Step : 3000 / 1\tCurrent Loss : 1.721610\n",
            "Current Step : 3200 / 1\tCurrent Loss : 1.576395\n",
            "Current Step : 3400 / 1\tCurrent Loss : 1.620174\n",
            "Current Step : 3600 / 1\tCurrent Loss : 1.628238\n",
            "Current Step : 3800 / 1\tCurrent Loss : 1.552439\n",
            "Current Step : 4000 / 1\tCurrent Loss : 1.664533\n",
            "Current Step : 4200 / 1\tCurrent Loss : 1.561585\n",
            "Current Step : 200 / 1\tCurrent Loss : 1.485202\n",
            "Current Step : 400 / 1\tCurrent Loss : 1.569732\n",
            "Current Step : 600 / 1\tCurrent Loss : 1.504317\n",
            "Current Step : 800 / 1\tCurrent Loss : 1.602374\n",
            "Current Step : 1000 / 1\tCurrent Loss : 1.526820\n",
            "Current Step : 1200 / 1\tCurrent Loss : 1.611679\n",
            "Current Step : 1400 / 1\tCurrent Loss : 1.524159\n",
            "Current Step : 1600 / 1\tCurrent Loss : 1.593435\n",
            "Current Step : 1800 / 1\tCurrent Loss : 1.676462\n",
            "Current Step : 2000 / 1\tCurrent Loss : 1.530550\n",
            "Current Step : 2200 / 1\tCurrent Loss : 1.581287\n",
            "Current Step : 2400 / 1\tCurrent Loss : 1.551893\n",
            "Current Step : 2600 / 1\tCurrent Loss : 1.584028\n",
            "Current Step : 2800 / 1\tCurrent Loss : 1.643976\n",
            "Current Step : 3000 / 1\tCurrent Loss : 1.515737\n",
            "Current Step : 3200 / 1\tCurrent Loss : 1.572432\n",
            "Current Step : 3400 / 1\tCurrent Loss : 1.521397\n",
            "Current Step : 3600 / 1\tCurrent Loss : 1.539120\n",
            "Current Step : 3800 / 1\tCurrent Loss : 1.567489\n",
            "Current Step : 4000 / 1\tCurrent Loss : 1.544102\n",
            "Current Step : 4200 / 1\tCurrent Loss : 1.616418\n",
            "Current Step : 200 / 1\tCurrent Loss : 1.487224\n",
            "Current Step : 400 / 1\tCurrent Loss : 1.556166\n",
            "Current Step : 600 / 1\tCurrent Loss : 1.542804\n",
            "Current Step : 800 / 1\tCurrent Loss : 1.455011\n",
            "Current Step : 1000 / 1\tCurrent Loss : 1.562478\n",
            "Current Step : 1200 / 1\tCurrent Loss : 1.577437\n",
            "Current Step : 1400 / 1\tCurrent Loss : 1.471164\n",
            "Current Step : 1600 / 1\tCurrent Loss : 1.579313\n",
            "Current Step : 1800 / 1\tCurrent Loss : 1.541025\n",
            "Current Step : 2000 / 1\tCurrent Loss : 1.654021\n",
            "Current Step : 2200 / 1\tCurrent Loss : 1.714930\n",
            "Current Step : 2400 / 1\tCurrent Loss : 1.499698\n",
            "Current Step : 2600 / 1\tCurrent Loss : 1.536068\n",
            "Current Step : 2800 / 1\tCurrent Loss : 1.505961\n",
            "Current Step : 3000 / 1\tCurrent Loss : 1.632627\n",
            "Current Step : 3200 / 1\tCurrent Loss : 1.505548\n",
            "Current Step : 3400 / 1\tCurrent Loss : 1.539017\n",
            "Current Step : 3600 / 1\tCurrent Loss : 1.617364\n",
            "Current Step : 3800 / 1\tCurrent Loss : 1.580199\n",
            "Current Step : 4000 / 1\tCurrent Loss : 1.550247\n",
            "Current Step : 4200 / 1\tCurrent Loss : 1.549836\n",
            "Current Step : 200 / 1\tCurrent Loss : 1.623846\n",
            "Current Step : 400 / 1\tCurrent Loss : 1.656389\n",
            "Current Step : 600 / 1\tCurrent Loss : 1.538466\n",
            "Current Step : 800 / 1\tCurrent Loss : 1.561317\n",
            "Current Step : 1000 / 1\tCurrent Loss : 1.626703\n",
            "Current Step : 1200 / 1\tCurrent Loss : 1.579913\n",
            "Current Step : 1400 / 1\tCurrent Loss : 1.584391\n",
            "Current Step : 1600 / 1\tCurrent Loss : 1.555939\n",
            "Current Step : 1800 / 1\tCurrent Loss : 1.574186\n",
            "Current Step : 2000 / 1\tCurrent Loss : 1.454462\n",
            "Current Step : 2200 / 1\tCurrent Loss : 1.501214\n",
            "Current Step : 2400 / 1\tCurrent Loss : 1.477231\n",
            "Current Step : 2600 / 1\tCurrent Loss : 1.550129\n",
            "Current Step : 2800 / 1\tCurrent Loss : 1.561093\n",
            "Current Step : 3000 / 1\tCurrent Loss : 1.503420\n",
            "Current Step : 3200 / 1\tCurrent Loss : 1.536316\n",
            "Current Step : 3400 / 1\tCurrent Loss : 1.563710\n",
            "Current Step : 3600 / 1\tCurrent Loss : 1.398408\n",
            "Current Step : 3800 / 1\tCurrent Loss : 1.606995\n",
            "Current Step : 4000 / 1\tCurrent Loss : 1.497517\n",
            "Current Step : 4200 / 1\tCurrent Loss : 1.548422\n",
            "Current Step : 200 / 1\tCurrent Loss : 1.476289\n",
            "Current Step : 400 / 1\tCurrent Loss : 1.519182\n",
            "Current Step : 600 / 1\tCurrent Loss : 1.601674\n",
            "Current Step : 800 / 1\tCurrent Loss : 1.475457\n",
            "Current Step : 1000 / 1\tCurrent Loss : 1.570712\n",
            "Current Step : 1200 / 1\tCurrent Loss : 1.603530\n",
            "Current Step : 1400 / 1\tCurrent Loss : 1.473954\n",
            "Current Step : 1600 / 1\tCurrent Loss : 1.401426\n",
            "Current Step : 1800 / 1\tCurrent Loss : 1.376996\n",
            "Current Step : 2000 / 1\tCurrent Loss : 1.530705\n",
            "Current Step : 2200 / 1\tCurrent Loss : 1.519115\n",
            "Current Step : 2400 / 1\tCurrent Loss : 1.421812\n",
            "Current Step : 2600 / 1\tCurrent Loss : 1.506888\n",
            "Current Step : 2800 / 1\tCurrent Loss : 1.487530\n",
            "Current Step : 3000 / 1\tCurrent Loss : 1.481307\n",
            "Current Step : 3200 / 1\tCurrent Loss : 1.582936\n",
            "Current Step : 3400 / 1\tCurrent Loss : 1.437915\n",
            "Current Step : 3600 / 1\tCurrent Loss : 1.441252\n",
            "Current Step : 3800 / 1\tCurrent Loss : 1.426458\n",
            "Current Step : 4000 / 1\tCurrent Loss : 1.575552\n",
            "Current Step : 4200 / 1\tCurrent Loss : 1.412273\n",
            "Current Step : 200 / 1\tCurrent Loss : 1.534706\n",
            "Current Step : 400 / 1\tCurrent Loss : 1.569121\n",
            "Current Step : 600 / 1\tCurrent Loss : 1.429396\n",
            "Current Step : 800 / 1\tCurrent Loss : 1.489149\n",
            "Current Step : 1000 / 1\tCurrent Loss : 1.549700\n",
            "Current Step : 1200 / 1\tCurrent Loss : 1.500865\n",
            "Current Step : 1400 / 1\tCurrent Loss : 1.540375\n",
            "Current Step : 1600 / 1\tCurrent Loss : 1.517103\n",
            "Current Step : 1800 / 1\tCurrent Loss : 1.479754\n",
            "Current Step : 2000 / 1\tCurrent Loss : 1.489517\n",
            "Current Step : 2200 / 1\tCurrent Loss : 1.621579\n",
            "Current Step : 2400 / 1\tCurrent Loss : 1.562442\n",
            "Current Step : 2600 / 1\tCurrent Loss : 1.567195\n",
            "Current Step : 2800 / 1\tCurrent Loss : 1.478946\n",
            "Current Step : 3000 / 1\tCurrent Loss : 1.514536\n",
            "Current Step : 3200 / 1\tCurrent Loss : 1.429442\n",
            "Current Step : 3400 / 1\tCurrent Loss : 1.529621\n",
            "Current Step : 3600 / 1\tCurrent Loss : 1.448016\n",
            "Current Step : 3800 / 1\tCurrent Loss : 1.543091\n",
            "Current Step : 4000 / 1\tCurrent Loss : 1.480514\n",
            "Current Step : 4200 / 1\tCurrent Loss : 1.645923\n",
            "Current Step : 200 / 1\tCurrent Loss : 1.553931\n",
            "Current Step : 400 / 1\tCurrent Loss : 1.601117\n",
            "Current Step : 600 / 1\tCurrent Loss : 1.490742\n",
            "Current Step : 800 / 1\tCurrent Loss : 1.443614\n",
            "Current Step : 1000 / 1\tCurrent Loss : 1.527789\n",
            "Current Step : 1200 / 1\tCurrent Loss : 1.513663\n",
            "Current Step : 1400 / 1\tCurrent Loss : 1.458544\n",
            "Current Step : 1600 / 1\tCurrent Loss : 1.431709\n",
            "Current Step : 1800 / 1\tCurrent Loss : 1.489664\n",
            "Current Step : 2000 / 1\tCurrent Loss : 1.447175\n",
            "Current Step : 2200 / 1\tCurrent Loss : 1.427618\n",
            "Current Step : 2400 / 1\tCurrent Loss : 1.553750\n",
            "Current Step : 2600 / 1\tCurrent Loss : 1.574201\n",
            "Current Step : 2800 / 1\tCurrent Loss : 1.517393\n",
            "Current Step : 3000 / 1\tCurrent Loss : 1.487167\n",
            "Current Step : 3200 / 1\tCurrent Loss : 1.449974\n",
            "Current Step : 3400 / 1\tCurrent Loss : 1.525325\n",
            "Current Step : 3600 / 1\tCurrent Loss : 1.482240\n",
            "Current Step : 3800 / 1\tCurrent Loss : 1.538406\n",
            "Current Step : 4000 / 1\tCurrent Loss : 1.398198\n",
            "Current Step : 4200 / 1\tCurrent Loss : 1.635839\n",
            "Current Step : 200 / 1\tCurrent Loss : 1.726423\n",
            "Current Step : 400 / 1\tCurrent Loss : 1.431996\n",
            "Current Step : 600 / 1\tCurrent Loss : 1.521895\n",
            "Current Step : 800 / 1\tCurrent Loss : 1.534115\n",
            "Current Step : 1000 / 1\tCurrent Loss : 1.486989\n",
            "Current Step : 1200 / 1\tCurrent Loss : 1.416170\n",
            "Current Step : 1400 / 1\tCurrent Loss : 1.429403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXcAp4hQMGXR",
        "outputId": "33ba854c-cbc7-48ae-a734-f0e38c22977b"
      },
      "source": [
        "if(__name__==\"__main__\"):\n",
        "\n",
        "    root_dir = \"/gdrive/My Drive/colab/transformer/chatbot/\"\n",
        "    output_dir = os.path.join(root_dir, \"output\")\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    config = {\"mode\": \"test\",\n",
        "              \"vocab_file\": os.path.join(root_dir, \"vocab.txt\"),\n",
        "              \"train_file\": os.path.join(root_dir, \"train.txt\"),\n",
        "              \"trained_model_name\":\"epoch_{}.pt\".format(10),\n",
        "              \"output_dir\":output_dir,\n",
        "              \"epoch\": 10,\n",
        "              \"learn_rate\":0.00005,\n",
        "              \"num_encoder_layers\": 6,\n",
        "              \"num_decoder_layers\": 6,\n",
        "              \"num_heads\": 4,\n",
        "              \"max_length\": 20,\n",
        "              \"batch_size\": 128,\n",
        "              \"embedding_size\": 256,\n",
        "              \"hidden_size\": 512,\n",
        "              \"vocab_size\": 4427\n",
        "            }\n",
        "\n",
        "    if(config[\"mode\"] == \"train\"):\n",
        "        train(config)\n",
        "    else:\n",
        "        test(config)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 안녕하세요\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "안녕하세요\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 밥은 먹었어?\n",
            "아니 아직 안먹었어\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 부대찌개 먹을래?\n",
            "아 그래?\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 우리 놀러가자!\n",
            "아 그래?\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 영화 보러 갈래요?\n",
            "네 ㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎㅎ\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 학교 같이 가자\n",
            "그래서 그런가\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 지금 뭐하고 있어?\n",
            "나 일하고 있어\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 무슨 일?\n",
            "그냥 그냥 그냥 그냥 그냥 먹어야지\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 무슨 말이야?\n",
            "그냥 그냥 그냥 그냥 그냥 먹어야지\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 뭘 먹는다고?\n",
            "그래서 그런가\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 뭐 먹을래?\n",
            "아니 그냥 먹어야지\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 밥 먹을래?\n",
            "아니 그냥 먹었어\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 야구 보자\n",
            "{share:photo}\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 사진 잘 봤어\n",
            "아 그래?\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 취미가 뭐야\n",
            "안녕하세요\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 음악 좋아해?\n",
            "나는 좋아해\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 질문 해줘\n",
            "그래서 그런거 같아\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 어디 살아?\n",
            "아니 그 그 영화 보고 있어\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 몇 살 이야?\n",
            "10000원\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 얼마야?\n",
            "1000원\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 돈 좀 빌려줘\n",
            "그래서 그런가봐\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 돈 많아?\n",
            "그래서 그런가\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 친구들이랑 놀자\n",
            "ㅋㅋㅋㅋㅋㅋㅋ\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 우리 집에 놀러와\n",
            "그래서 그런가\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 집이 어디야?\n",
            "아니 집에서 가서 먹어야지\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : exit\n"
          ]
        }
      ]
    }
  ]
}